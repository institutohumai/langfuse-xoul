# Core
NODE_ENV=production
NEXTAUTH_SECRET=somesecret
SALT=somesalt
# 64 hex chars (256-bit): openssl rand -hex 32
ENCRYPTION_KEY=xxxxxxxxxx

# Web external URL
NEXTAUTH_URL=http://EXTERNAL_VM_IP:3000

# Postgres via Cloud SQL Auth Proxy on the VM host
# If proxy runs on the VM host:
DATABASE_URL=postgresql://SOMUSER:PASSWORD@host.docker.internal:5432/langfuse
# If you run the proxy as a compose service named 'cloud-sql-proxy', then:
# DATABASE_URL=postgresql://DB_USER:DB_PASSWORD@cloud-sql-proxy:5432/DB_NAME
# USER must have create db permissions if not set following var:
# SHADOW_DATABASE_URL=

# ClickHouse (matches container config in docker-compose.yml)
CLICKHOUSE_USER=clickhouse
CLICKHOUSE_PASSWORD=clickhouse
CLICKHOUSE_DB=default

# Redis must match the Redis container password in docker-compose.yml
REDIS_AUTH=myredissecret

# Telemetry (optional)
TELEMETRY_ENABLED=true

# Experimental features (optional)
LANGFUSE_ENABLE_EXPERIMENTAL_FEATURES=true

# GCS settings
LANGFUSE_USE_GOOGLE_CLOUD_STORAGE=true
# Buckets you created in GCP (must exist; VMâ€™s service account needs storage access)
LANGFUSE_S3_EVENT_UPLOAD_BUCKET=events-bucket
LANGFUSE_S3_EVENT_UPLOAD_PREFIX=events/
# Optional media uploads
LANGFUSE_S3_MEDIA_UPLOAD_BUCKET=media-bucket
# Optional batch exports
LANGFUSE_S3_BATCH_EXPORT_ENABLED=true
LANGFUSE_S3_BATCH_EXPORT_BUCKET=exports-bucket

# Credentials: omit to use the VM's service account (ADC)
# LANGFUSE_GOOGLE_CLOUD_STORAGE_CREDENTIALS=/secrets/gcs.json